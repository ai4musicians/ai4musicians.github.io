<!DOCTYPE HTML>
<!--
    Hyperspace by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html lang="en" xml:lang="en">

<head>
    <title>AI (Artificial Intelligence) for Musicians</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>
</head>

<body class="is-preload">

    <!-- Sidebar -->
    <section id="sidebar">
        <div class="inner">
            <nav>
                <ul>
                    <li><a href="#intro"><img src="images/aim.png" alt="AIM logo" width=50></a></li>
                    <li><a href="#amt">Our Projects</a></li>
                    <li><a href="#activities">Research Areas</a></li>
                    <li><a href="#who">Leaders</a></li>
                    <li><a href="#outreach">Outreach</a></li>
                    <li><a href="#vipteam">VIP Team</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </div>
    </section>

    <!-- Wrapper -->
    <div id="wrapper">
        <ul>
            <li> News: <a href="2025robot.html">Workshop "Robotic Musician" in 2025 </a> </li>
            <li> News: <a href="2025aaai.html">Workshop "AI for Music" in 2025 AAAI </a> </li>
            <li> News: <a href="transcription/2025transcription.html">2025 Transcription Competition </a> </li>
        </ul>

        <!-- Intro -->
        <section id="intro" class="wrapper style1 fullscreen fade-up">
            <div class="inner">
                <!-- -		<img src="images/aim.png" style="width:100%" alt="" data-position="top center" /> - -->
                <h1>Welcome to AIM.</h1>
                <p> <b>AIM (Artificial Intelligence for Musicians) </b> is a Purdue <b>music technology research
                        group</b>, whose aim is to create reactive, human-like systems which support musicians during
                    their practice sessions and performances.</p>
                <p> Some of AIM's projects are supported by <a
                        href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2326198">a National Science Foundation
                        grant</a>.</p>
                <p> We are looking for motivated graduate or undergraduate students to join our team. <a
                        href="vip_info.html">Click here for info.</a></p>
                <iframe
                    src="https://ghbtns.com/github-btn.html?user=Purdue-Artificial-Intelligence-in-Music&type=follow&count=true&size=large"
                    frameborder="0" scrolling="0" width="500" height="30" title="GitHub"></iframe>
            </div>
        </section>

        <!-- AMT -->
        <section id="amt" class="wrapper style3 spotlights">
            <section>
                <a href="#" class="image"><img src="images/amt.jpeg" style="width:100%" alt=""
                        data-position="top center" /></a>
                <div class="content">

                    <div class="inner">
                        <h2><a
                                href="https://github.com/Purdue-Artificial-Intelligence-in-Music/music-transcription">Automatic Music Transcription</a>
                        </h2>
                        <h4>Fall 2024 - present</h4>
                        <p>
                            Automatic Music Transcription is a project focused on streamlining audio-to-MIDI transcription for musicians and educators, with applications in isolating sounds in noisy environments. We are conducting a systematic review of AMT models, examining their strengths and limitations with complex, multi-instrument music. To drive innovation, we're hosting a competition in April 2025, challenging participants to create accurate transcription models for classical music. This project aims to drive advancements in AMT and refine current transcription methods.
                        </p>
                    </div>
                </div>
            </section>
        </section>

        <!-- Evaluator -->
        <section id="evaluator" class="wrapper style4 spotlights">
            <section>
                <a href="#" class="image"><img src="images/evaluator.jpg" alt=""
                        data-position="top left" /></a>
                <div class="content">

                    <div class="inner">
                        <h2><a
                                href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Evaluator-code">Evaluator</a>
                        </h2>
                        <h4>Fall 2023 - present</h4>
                        <p>
                            Evaluator is an app that aims to help musicians practice more effectively. It utilizes
                            computer vision and YOLO localization techniques to help musicians track, analyze, and
                            improve their posture. It also uses spectrogram analysis and multi-modal transformers to
                            help the musicians identify their mistakes in music and correct them. </p>
                        Drawing by Cecilia Ines Sanchez.

                        <!---
			<p>This project will develop and integrate techniques to create two AI-enabled tools to support string music performers. The first tool, the Evaluator, aims to improve individual practice and performance. It analyzes a musician’s sound and compares it to digitized music scores to detect deviations in intonation, rhythm, and dynamics and suggest better posture based on sample performers’ recording with correct posture. The second tool, the Companion, plays the part of one or several instruments to replace absent musicians with matching tempo, and style of the human musicians through audio analysis of their performance while also responding in real-time to verbal instructions. </p>
			--->
                    </div>
                </div>
            </section>
        </section>

        <!-- Companion -->
        <section id="companion" class="wrapper style5 spotlights">
            <section>
                <a href="#" class="image"><img src="images/companion.png" style="width:100%" alt=""
                        data-position="top center" /></a>
                <div class="content">
                    <div class="inner">
                        <h2><a
                                href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Companion-code">Companion</a>
                        </h2>
                        <h4>Fall 2023 - present</h4>
                        <p>
                            Companion is an app that not only plays along with a human player during a chamber music
                            piece, but actively responds to their playing habits and voice commands like a real human
                            would. The project involves machine learning and filtering/DSP algorithms to analyze and
                            edit sound quickly and accurately and utilizes small NLP language models for voice command
                            implementation.
                        </p>
                        Drawing by Cecilia Ines Sanchez.
                    </div>
                </div>
            </section>
        </section>


        <!-- Visualize -->
        <section id="mus2vid" class="wrapper style6 spotlights">
            <section>
                <a href="#" class="image"><img src="images/visualizemusic.png" style="width:100%" alt=""
                        data-position="top center" /></a>
                <div class="content">
                    <div class="inner">
                        <h2><a
                                href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Mus2Vid-code">Mus2Vid</a>
                        </h2>
                        <h4>Spring 2022 - present</h4>
                        <p>Mus2Vid is a real-time art project that uses diffusion models to generate video depictions in
                            response to classical music. It uses recurrent and transformer networks to analyze input
                            audio and estimate its emotion and genre qualities, which are converted into text and fed to
                            a text-to-image diffusion model to generate images.

                        <ul class="actions">
                            <li><a href="visualize.html" class="button scrolly">Learn more</a></li>
                        </ul>
                    </div>
                </div>
            </section>
        </section>

        <!-- Robot Cello -->
        <section id="robotcello" class="wrapper style7 spotlights">
            <section>
                <iframe width=25% src="https://www.youtube.com/embed/Rf0bSJr8yFM?si=6LKA8egAhXsrftlh"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                    allowfullscreen></iframe>

                <div class="content">
                    <div class="inner">
                        <h2>Robot Cello</h2>
                        <h4>Spring 2024 - present</h4>
                        <p> As the name suggests, Robot Cello is a project about using reinforcement learning to teach a
                            robot arm to play cello. The project is currently in its survey phase but is currently
                            investigating using motion capture technology to get training data for an RL model.
                        <p> We partner with the <a href="https://www.rcac.purdue.edu/envision">Purdue Envision
                                Center</a> to collect motion data for our robot arm to train on. On the left is a video
                            of Prof. Yun playing cello while wearing a motion-capture rig.</p>
                    </div>
                </div>
            </section>
        </section>


        <section id="activities" class="wrapper style8 fade-up">
            <div class="inner">
                <h2>Research Areas + Questions</h2>
                <p>Our projects often span most or all of these areas, as they are all important to making effective,
                    human-like music technology.</p>
                <div class="features">
                    <section>
                        <span class="icon solid major fa-volume-up"></span>
                        <h3>Generative Audio and DSP</h3>
                        <p>How can Companion utilize machine learning and filtering to resynthesize string instrument
                            articulations on-the-fly?</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-stopwatch"></span>
                        <h3>Beat Detection and Tempo Tracking</h3>
                        <p>What are the most effective methods for Companion, Evaluator, and Mus2Vid to follow a
                            musician's playing in reference to a score, and play along to match?</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-eye"></span>
                        <h3>Emotion and Perception</h3>
                        <p>How can Mus2Vid analyze emotion of classical music in real-time and utilize it to generate
                            real-time video accompaniments?</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-music"></span>
                        <h3>Music Classification/Information Retrieval</h3>
                        <p>What musical features extracted from various media, such as tempo, key, genre, notes, are
                            useful to music performance technology, and how can we extract such features?</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-users"></span>
                        <h3>Human-Computer Interaction</h3>
                        <p>How can our apps be designed in ways that are human-like and natural for humans to interact
                            with?</p>
                    </section>
                    <section>
                        <span class="icon major fa-comments"></span>
                        <h3>User Studies + Deployments</h3>
                        <p>How can we ensure that our users actually utilize and enjoy the apps we develop?</p>
                    </section>
                </div>
                <!---
	  <ul class="actions">
	    <li><a href="generic.html" class="button">Learn more</a></li>
	  </ul>
	  --->
            </div>
        </section>


        <!-- who -->
        <section id="who" class="wrapper style9 spotlights">
            <section>
                <div class="content">
                    <div class="inner">
                        <h2>Meet the team! </h2>
                        <img src="images/aim_photo.jpg" style="width:100%" alt="" data-position="top center" />
                        <p>Our team comes from a wide variety of backgrounds, including the Purdue Colleges of
                            Engineering, Science, Liberal Arts, Management, and more. We have a mix of Purdue
                            professors, graduate students, and undergraduate students leading our projects and research
                            efforts.</p>
                        <a href="the_team.html" class="button scrolly">Learn more</a>
                    </div>
                </div>
            </section>
        </section>

        <section id="outreach" class="wrapper style10 fade-up">
            <div class="inner">
                <h2>Outreach</h2>
                <p>Here are some of the ways AIM ensures that it is integrated with both Purdue's local community and
                    the global community.</p>
                <div class="features">
                    <section>
                        <span class="icon solid major fa-school"></span>
                        <h3>Vertically Integrated Project</h3>
                        <p>AIM has an associated Vertically Integrated Project, which enables research experiences for
                            Purdue undergraduates.
                        <ul class="actions">
                            <li><a href="#vipteam" class="button scrolly">Learn More</a></li>
                        </ul>
                        </p>
                    </section>
                    <section>
                        <span class="icon solid major fa-microscope"></span>
                        <h3>Multidisciplinary Research</h3>
                        <p>Music technology is a field with very multidisciplinary problems and solutions. As such, we
                            draw from a wide variety of departments for our talent, including Music, Electrical and
                            Computer Engineering, Computer Science, Technology, Art, Design, and Management.</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-comments"></span>
                        <h3>User Studies</h3>
                        <p>AIM actively runs user studies on the tools that are developed to ensure that users can
                            figure out how to use them and enjoy them.</p>
                    </section>
                    <section>
                        <span class="icon solid major fa-ticket-alt"></span>
                        <h3>Presentations/Concerts</h3>
                        <p>AIM members have given speeches, presentations, and concerts about and using AIM technology
                            around the world.</p>
                    </section>
                </div>
                <!---
	  <ul class="actions">
	    <li><a href="generic.html" class="button">Learn more</a></li>
	  </ul>
	  --->
            </div>
        </section>

        <!-- VIP Team -->
        <section id="vipteam" class="wrapper style11 fade-up">
            <div class="inner">
                <!---<img src="images/vip-web.jpg" style="width:100%" /> --->
                <h1>Vertically Integrated Projects Team</h1>

                <p> AIM stands out among other music technology research groups because of its pedagogy. While other
                    music technology groups may cater primarily to graduate students and professionals, our group is
                    open to all Purdue students of any major and experience level. </p>
                <p> We hope that by helping any student interested in music technology/machine learning learn to work
                    with these technologies, we can make a difference in these students' lives while simultaneously
                    encouraging the adoption of music technology.</p>
                <ul class="actions">
                    <li><a href="vip_info.html" class="button scrolly">Learn more</a></li>
                </ul>
                <a href="#" class="image"><img src="images/companionteam20240125.jpg" style="width:100%" alt="team"
                        data-position="fit" /></a>
            </div>
        </section>



        <!-- Contact -->
        <section id="contact" class="wrapper style12 fade-up">
            <div class="inner">
                <img src="images/aim.png" width="100" alt="" data-position="top center" />
                <h2>Get In Touch With Us!</h2>
                <div class="style1">
                    <section>
                        <ul class="contact">
                            <li>
                                <h3>Email</h3>General inquiry: <a href="mailto:yun98@purdue.edu">yun98@purdue.edu</a>
                                <br>VIP team-related inquiries: <a href="mailto:yunglu@purdue.edu">yunglu@purdue.edu</a>
                                </p>
                            </li>
                            <li>
                                <h3>Phone Number</h3>
                                <span>(765) 494-0973</span>
                            </li>
                            <li>
                                <h3>Social</h3>
                                <ul class="icons">
                                    <li><a href="https://www.linkedin.com/in/kristen-yeon-ji-yun-72112591/"
                                            class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                    </section>
                </div>
            </div>
        </section>

    <!-- Footer -->
    <footer id="footer" class="wrapper">
        <div class="inner">
            <ul class="menu">
                <li>&copy; Purdue AIM 2024. All rights reserved.</li>
                <li>Design: <a href="http://html5up.net">HTML5 UP</a>, modified by Ojas Chaturvedi</li>
                <li> <a href="http://html5up.net/license">Creative Commons</a>.</p>
            </ul>
        </div>
    </footer>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>