<!DOCTYPE HTML>
<!--
    Hyperspace by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
  -->
<html>
  <head>
    <title>AI (Artificial Intelligence) for Musicians</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
  </head>
  <body class="is-preload">

    <!-- Sidebar -->
    <section id="sidebar">
      <div class="inner">
		
	<nav>
		
	  <ul>
		<li><a href="#intro"><img src="images/aim.png" width=50></img></a></li>
		<li><a href="#evaluator">Our Projects</a></li>
	    <li><a href="#activities">Research Areas</a></li>
	    <li><a href="#who">Leaders</a></li>
		<li><a href="#outreach">Outreach</a></li>
	    <li><a href="#vipteam">VIP Team</a></li>
	    <li><a href="#contact">Contact</a></li>
	  </ul>
	</nav>
      </div>
    </section>

    <!-- Wrapper -->
    <div id="wrapper">

      <!-- Intro -->
      <section id="intro" class="wrapper style1 fullscreen fade-up">
	<div class="inner">
		<img src="images/aim.png" width="200" alt="" data-position="top center" />
	  <h1>Welcome to AIM.</h1>
	  <p> <b>AIM (Artificial Intelligence for Musicians) </b> is a Purdue <b>music technology research group</b>, whose aim is to create reactive, human-like systems which support musicians during their practice sessions and performances.</p>
	  <p> Some of AIM's projects are supported by <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2326198">a National Science Foundation grant</a>.</p>
	  <p> We are looking for motivated graduate or undergraduate students to join our team. <a href="vip_info.html">Click here for info.</a></p>
	  <h2>See what we're making below:</h2>
	    <!---
	    <ul class="actions">
	      <li><a href="#one" class="button scrolly">Learn more</a></li>
	    </ul>
	    --->
	</div>
      </section>

	<!-- Evaluator -->
		
	<section id="evaluator" class="wrapper style3 spotlights">
		<section>
		<a href="#" class="image"><img src="images/evaluator.jpg" width="300" alt="" data-position="top center" /></a> 
		<div class="content">
			
		  <div class="inner">
			<h2><a href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Evaluator-code">Evaluator</a></h2>
			<h4>Fall 2023 - present</h4>
			<p>
			Evaluator is an app that aims to help musicians practice more effectively. It utilizes computer vision and YOLO localization techniques to help musicians track, analyze, and improve their posture. It also uses spectrogram analysis and multi-modal transformers to help the musicians identify their mistakes in music and correct them. </p>
			Drawing by Cecilia Ines Sanchez.
  
			<!---
			<p>This project will develop and integrate techniques to create two AI-enabled tools to support string music performers. The first tool, the Evaluator, aims to improve individual practice and performance. It analyzes a musician’s sound and compares it to digitized music scores to detect deviations in intonation, rhythm, and dynamics and suggest better posture based on sample performers’ recording with correct posture. The second tool, the Companion, plays the part of one or several instruments to replace absent musicians with matching tempo, and style of the human musicians through audio analysis of their performance while also responding in real-time to verbal instructions. </p>
			--->
		  </div>
		</div>
	  </section>
	</section>

	 <!-- Companion -->
	  <section id="companion" class="wrapper style2 spotlights">
		<section>
		<a href="#" class="image"><img src="images/companion.png" width="300" alt="" data-position="top center" /></a>
		<div class="content">
		  <div class="inner">
			<h2><a href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Companion-code">Companion</a></h2>
			<h4>Fall 2023 - present</h4>
			<p>
		  Companion is an app that not only plays along with a human player during a chamber music piece, but actively responds to their playing habits and voice commands like a real human would. The project involves machine learning and filtering/DSP algorithms to analyze and edit sound quickly and accurately and utilizes small NLP language models for voice command implementation. 
		</p>
			Drawing by Cecilia Ines Sanchez.
		  </div>
		</div>
	  </section>
	</section>
  
  
	  <!-- Visualize -->
	  <section id="mus2vid" class="wrapper style1 spotlights">
		<section>
		<a href="#" class="image"><img src="images/visualizemusic.png" width="300" alt="" data-position="top center" /></a>
		<div class="content">
		  <div class="inner">
			<h2><a href="https://github.com/Purdue-Artificial-Intelligence-in-Music/Mus2Vid-code">Mus2Vid</a></h2>
			<h4>Spring 2022 - present</h4>
			<p>Mus2Vid is a real-time art project that uses diffusion models to generate video depictions in response to classical music. It uses recurrent and transformer networks to analyze input audio and estimate its emotion and genre qualities, which are converted into text and fed to a text-to-image diffusion model to generate images.

		  <ul class="actions">
			<li><a href="visualize.html" class="button scrolly">Learn more</a></li>
		  </ul>
		  </div>
		</div>
	</section>
	  </section>

	   <!-- Robot Cello -->
	  <section id="robotcello" class="wrapper style4 spotlights">
		<section>
		<iframe width=100% src="https://www.youtube.com/embed/Rf0bSJr8yFM?si=6LKA8egAhXsrftlh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	
		<div class="content">
		  <div class="inner">
			<h2>Robot Cello</h2>
			<h4>Spring 2024 - present</h4>
			<p> As the name suggests, Robot Cello is a project about using reinforcement learning to teach a robot arm to play cello. The project is currently in its survey phase but is currently investigating using motion capture technology to get training data for an RL model. 
			<p> We partner with the <a href="https://www.rcac.purdue.edu/envision">Purdue Envision Center</a> to collect motion data for our robot arm to train on. On the left is a video of Prof. Yun playing cello while wearing a motion-capture rig.</p>
				  </div>
		</div>
	</section>
	  </section>

      
      <section id="activities" class="wrapper style3 fade-up">
	<div class="inner">
	  <h2>Research Areas + Questions</h2>
	  <p>Our projects often span most or all of these areas, as they are all important to making effective, human-like music technology.</p>
	  <div class="features">
	    <section>
	      <span class="icon solid major fa-volume-up"></span>
	      <h3>Generative Audio and DSP</h3>
	      <p>How can Companion utilize machine learning and filtering to resynthesize string instrument articulations on-the-fly?</p>
	    </section>
	    <section>
	      <span class="icon solid major fa-stopwatch"></span>
	      <h3>Beat Detection and Tempo Tracking</h3>
	      <p>What are the most effective methods for Companion, Evaluator, and Mus2Vid to follow a musician's playing in reference to a score, and play along to match?</p>
	    </section>
	    <section>
	      <span class="icon solid major fa-eye"></span>
	      <h3>Emotion and Perception</h3>
	      <p>How can Mus2Vid analyze emotion of classical music in real-time and utilize it to generate real-time video accompaniments?</p>
	    </section>
		<section>
			<span class="icon solid major fa-music"></span>
			<h3>Music Classification/Information Retrieval</h3>
			<p>What musical features extracted from various media, such as tempo, key, genre, notes, are useful to music performance technology, and how can we extract such features?</p>
		  </section>
	    <section>
	      <span class="icon solid major fa-users"></span>
	      <h3>Human-Computer Interaction</h3>
	      <p>How can our apps be designed in ways that are human-like and natural for humans to interact with?</p>
	    </section>
	    <section>
	      <span class="icon major fa-comments"></span>
	      <h3>User Studies + Deployments</h3>
	      <p>How can we ensure that our users actually utilize and enjoy the apps we develop?</p>
	    </section>
	  </div>
	  <!---
	  <ul class="actions">
	    <li><a href="generic.html" class="button">Learn more</a></li>
	  </ul>
	  --->
	</div>
      </section>

      
      <!-- who -->
	  <section id="who" class="wrapper style5 spotlights">
		<section>
		  <div class="content">
			<div class="inner">
			  <h2>Meet the team! </h2>
			  <p>Our team comes from a wide variety of backgrounds, including the Purdue Colleges of Engineering, Science, Liberal Arts, Management, and more. We have a mix of Purdue professors, graduate students, and undergraduate students leading our projects and research efforts.</p>
			</div>
		  </div>
		</section>
	</section>
      <section id="who" class="wrapper style5 spotlights">
	<section>
	  <a href="#" class="image"><img src="images/yun.jpg" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
	      <h2>Dr. Kristen Yeon-Ji Yun </h2>
		  <h3>Project Director</h3>
		  <h3>Clinical Associate Professor of Music</h3>
	      <p> <a href=https://www.cla.purdue.edu/directory/profiles/yeon-ji-kristen-yun.html>
			Kristen Yeon-Ji Yun </a> is a clinical associate professor in the Department of Music in the Patti and Rusty Rueff School of Design, 
			Art, and Performance at Purdue University. She is active as a soloist, chamber musician, musical scholar, and clinician. 
			Her recent CD “Summerland” has excellent reviews from New Classics UK, American Record Guide, 
			and was broadcast nationwide by radio stations such as WQXR, WCNY, WBAA, and NPR Sonatas and Soundscapes.
			She started this research group due to struggles she personally experienced while practicing and performing cello.</p>
	      <!---
	      <ul class="actions">
		<li><a href="generic.html" class="button">Learn more</a></li>
	      </ul>
	      --->
	    </div>
	  </div>
	</section>
	<section>
	  <a href="#" class="image"><img src="images/joshkamphuis.png" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
		  <h2>Josh Kamphuis </h2>
		  <h3>Evaluator Project Lead</h3>
		  <h3>Mus2Vid Contributor</h3>
	      <p>With an academic concentration on artificial intelligence and machine learning, and over 12 years of experience as a classical pianist, I am a past and present leader of two research projects analyzing music with AI. I led a team investigating audio input for image diffusion models, translating classical music into visual art in real time. Now, I lead a team developing an app to analyze and critique string musicians’ sound and posture using multiple streams of input – audio and video of performances, as well as digitized sheet music. Outside of research and schoolwork, I spend his time cooking, camping, and rock climbing.</p>
	      <!---
	      <h2>Undergraduate Research -  MUS2VID</h2>
              <p>Real-time generation of video accompaniment for classical music </p> --->
	      <!---
	      <ul class="actions">
		<li><a href="generic.html" class="button">Learn more</a></li>
	      </ul>
	      --->
	    </div>
	  </div>
	</section>
	<section>
	  <a href="#" class="image"><img src="images/timnadolsky.jpg" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
			<h2>Tim Nadolsky </h2>
		  <h3>Companion Project Lead</h3>
		  <h3>Mus2Vid Contributor</h3>
	      <p>Tim is the leader of the Companion project, as well as an active contributor to Mus2Vid. His interests lie primarily in building software systems that exhibit emotion in human-like ways, usually through the lens of music technology. In his free time, Tim composes and produces pop/electronic music, (badly) plays the piano, and enjoys casually travelling and hiking.</p>
		  <ul class="icons">
			<li><a href="https://www.linkedin.com/in/timusic/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
		      </ul>
	    </div>
	  </div>
	</section>
	</section>
	<section id="who" class="wrapper style5 spotlights">
	<section>
	  <a href="#" class="image"><img src="images/KareenaDPatel.jpg" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
			<h2>Kareena D. Patel</h2>
			<h3>Mus2Vid Project Lead</h3>
	      <p>Kareena is a leader of the Mus2Vid project. She has a genuine passion for learning and exploring new ideas. Whether it's diving into machine learning and deep neural networks or staying updated 
			with industry trends, she is always eager to expand my knowledge and skills. Outside of academics, Kareena likes to explore her creative endeavors 
			such as writing songs and playing the piano. She also has a passion for the outdoors, and enjoys kayaking and hiking.</p>
	    </div>
	  </div>
	</section>
	<section>
		<a href="#" class="image"><img src="images/haichangli.png" width="400" alt="" data-position="top center" /></a>
		<div class="content">
		  <div class="inner">
			<h2>Haichang Li</h2>
			<h3>Mus2Vid Project Lead</h3>
			<p>Haichang (Charles) Li (李海畅) is a leader of the Mus2Vid project. He is currently interested in Human-AI Collaboration, 
				specifically at the intersection of AGI and HCI (in especial creative works like Music & modeling). 
				His ideal role is to be the link and bridge between external observers and designers in this process. He hopes
				to explore how AI can better help human beings to achieve benign coexistence, such as in the fields of multi-modal a11y, 
				that is, to help people who need help more first and to explore the impact of AI on the world.</p>
		  </div>
		</div>
	  </section>
	<section>
	  <a href="#" class="image"><img src="images/SamanthaRoseSudhoff.png" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
			<h2>Samantha Rose Sudhoff</h2>
			<h3>Robot Cello Project Lead</h3>
	      <p>
			Hi! I am Sam, and I'm the leader of the Robot Cello project. I have experience with C/C++ systems programming, Java programming, data engineering using Python, database and SQL, and various other aspects of computer science. I am also minoring in psychology to understand better about human minds and the connection with AI.

			<br>In my free time, I enjoy playing cello, reading, and listening to classical music :) 
		  </p>
	    </div>
	  </div>
	</section>
	</section>
	<section id="who" class="wrapper style5 spotlights">
	<section>
	  <a href="#" class="image"><img src="images/brianng.png" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
			<h2>Brian Ng</h2>
			<h3>Former Mus2Vid Project Lead + Lab Alumni</h3>
	      <p>Brian was a founding member of Purdue AIM. He received his B.S.CmpE. from the Purdue College of Engineering in December 2023.</p>
	    </div>
	  </div>
	</section>
	<section>
	  <a href="#" class="image"><img src="https://polytechnic.purdue.edu/sites/default/files/styles/240px-wide/public/pictures/picture-652-1635264945.jpg?itok=b_Bvi856" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
	      <p>
			<h2>Dr. Victor Yingjie Chen</h2>
			<h3>Professor of Computer Graphics Technology</h3>
			<a href="https://polytechnic.purdue.edu/profile/chen489">Dr. Victor Yingjie Chen</a> is a professor of Computer Graphics Technology. His research covers interdisciplinary domains of Computer Graphics and Human-Computer Interaction, such as Information Visualization, Visual Analytics, Virtual Reality, and AI in Computer Graphics. He seeks to design, model, and construct new forms of interaction in visualization and system design, by which the system can minimize its influence on design and analysis, and become a true free extension of human’s brain and hand.</p>
	    </div>
	  </div>
	</section>
	<section>
	  <a href="#" class="image"><img src="https://engineering.purdue.edu/ResourceDB/ResourceFiles/image277153" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
	      <p>
			<h2>Dr. Yung-Hsiang Lu</h2>
			<h3>Professor of Electrical and Computer Engineering</h3>
	      <a href="https://engineering.purdue.edu/ECE/People/ptProfile?resource_id=3355l">
	      Dr. Yung-Hsiang Lu</a> is a professor of Electrical and Computer Engineering at Purdue University. He is a University Faculty Scholar of Purdue University. He is a fellow of the IEEE (Institute of Electrical and Electronics Engineers), distinguished visitor of the Computer Society, distinguished scientist and distinguished speaker of the ACM (Association for Computing Machinery). Dr. Lu is the inaugural director of Purdue’s John Martinson Engineering Entrepreneurial Center (2020-2022). In 2019, he received Outstanding VIP-Based Entrepreneur Award from the VIP (Vertically Integrated Projects) Consortium. His research areas include computer vision, embedded systems, cloud and mobile computing. Dr. Lu has advised 400 undergraduate students in research projects and taught more than 5,000 students in classrooms. He has advised multiple student teams winning business plan competitions; two teams of students started technology companies and raised more than $1.5M.</p>
	    </div>
	  </div>
	</section>
	</section>
	<section id="who" class="wrapper style5 spotlights">
	<section>
	  <a href="#" class="image"><img src="https://www.cla.purdue.edu/directory/images/cheryl-zhenyu-qian.jpg" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
	      <p>
			<h2>Dr. Cheryl Zhenyu Qian</h2>
			<h3>Professor of Industrial Design, Rueff School of Design, Art, and Performance</h3>
	      <a href="https://www.cla.purdue.edu/directory/profiles/cheryl-zhenyu-qian.html">
		Dr. Cheryl Zhenyu Qian</a> is a full professor of Interaction Design in Industrial Design at Purdue University. Being a boundary crosser, Dr. Qian is interested in studying and developing cognitive systems to enrich knowledge, employing interdisciplinary research methodologies to improve the design quality, and adopting innovative technologies to accommodate user experience. Her current research is focused on 1) the harmonious integration of physical and virtual interactions in the user experience design, 2) adopting interaction design theories, tools, and evaluation methods to review, compare, guide, and enhance product design outcomes, and 3) employing innovative design thinking into the domain of visual analytics. </p>
	    </div>
	  </div>
	</section>
	<section>
	  <a href="#" class="image"><img src="images/mohammadrahman.jpg" width="400" alt="" data-position="top center" /></a>
	  <div class="content">
	    <div class="inner">
	      <p>
			<h2>Dr. Mohammad Saifur Rahman</h2>
			<h3>Professor of Management, Daniels School Chair in Management</h3>
	      <a href="https://business.purdue.edu/directory/bio.php?username=mrahman">
	      Dr. Mohammad Saifur Rahman</a> Professor Mohammad Saifur Rahman is the inaugural Daniels School Chair in Management and a Professor of Management at the Mitchell E. Daniels, Jr. School of Business, Purdue University. He was named one of the World's Top 40 Business School Professors Under 40 by Poets and Quants in 2017. His research primarily focuses on digitization economics, omnichannel retailing, innovations and inequality, and AI and decision making. <br>
		  Professor Rahman has published in major journals including Management Science, Information Systems Research, and MIT Sloan Management Review. His papers have been accepted in several leading conferences, e.g., Workshop on Information Systems Economics (WISE), International Conference on Information Systems (ICIS), and Conference on Information Systems and Technology (CIST). Also, his research has been supported by multiple major Social Sciences and Humanities Research Council (SSHRC) grants. </p>
	    </div>
	  </div>
	</section>
</section>

<section id="outreach" class="wrapper style3 fade-up">
	<div class="inner">
	  <h2>Outreach</h2>
	  <p>Here are some of the ways AIM ensures that it is integrated with both Purdue's local community and the global community.</p>
	  <div class="features">
	    <section>
	      <span class="icon solid major fa-school"></span>
	      <h3>Vertically Integrated Project</h3>
	      <p>AIM has an associated Vertically Integrated Project, which enables research experiences for Purdue undergraduates.
			<ul class="actions">
			<li><a href="#vipteam" class="button scrolly">Learn More</a></li>
		  </ul></p>
	    </section>
	    <section>
	      <span class="icon solid major fa-microscope"></span>
	      <h3>Multidisciplinary Research</h3>
	      <p>Music technology is a field with very multidisciplinary problems and solutions. As such, we draw from a wide variety of departments for our talent, including Music, Electrical and Computer Engineering, Computer Science, Technology, Art, Design, and Management.</p>
	    </section>
	    <section>
	      <span class="icon solid major fa-comments"></span>
	      <h3>User Studies</h3>
	      <p>AIM actively runs user studies on the tools that are developed to ensure that users can figure out how to use them and enjoy them.</p>
	    </section>
	    <section>
	      <span class="icon solid major fa-ticket-alt"></span>
	      <h3>Presentations/Concerts</h3>
	      <p>AIM members have given speeches, presentations, and concerts about and using AIM technology around the world.</p>
	    </section>
	  </div>
	  <!---
	  <ul class="actions">
	    <li><a href="generic.html" class="button">Learn more</a></li>
	  </ul>
	  --->
	</div>
      </section>
	
	<!-- VIP Team -->
	<section id="vipteam" class="wrapper style2 fullscreen fade-up">
		<div class="inner">
		  <img src="images/vip-web.jpg" width="200" />
		  <h1>Vertically Integrated Projects Team</h1>
		  
		  <p> AIM stands out among other music technology research groups because of its pedagogy. While other music technology groups may cater primarily to graduate students and professionals, our group is open to all Purdue students of any major and experience level. </p>
		  <p> We hope that by helping any student interested in music technology/machine learning learn to work with these technologies, we can make a difference in these students' lives while simultaneously encouraging the adoption of music technology.</p> 
		  <ul class="actions">
			<li><a href="vip_info.html" class="button scrolly">Learn more</a></li>
		  </ul>
		  <a href="#" class="image"><img src="images/companionteam20240125.jpg"  alt="" data-position="fit" /></a>
		</div>
	</section>
	
	
      
      <!-- Contact -->
      <section id="contact" class="wrapper style5 fade-up">
	<div class="inner">
		<img src="images/aim.png" width="100" alt="" data-position="top center" />
	  <h2>Get in touch</h2>
	  <div class="split style1">
		<section>
		  <ul class="contact">
		    <li>
		      <h3>Email</h3>General inquiry: <a href="mailto:yun98@purdue.edu">yun98@purdue.edu</a>
			<br>VIP team-related inquiries: <a href="mailto:yunglu@purdue.edu">yunglu@purdue.edu</a> or <a href="mailto:tnadolsk@purdue.edu">tnadolsk@purdue.edu</a></p>
		    </li>
		    <li>
		      <h3>Phone</h3>
		      <span>(765) 494-0973</span>
		    </li>
		    <li>
		      <h3>Social</h3>
		      <ul class="icons">
			<li><a href="https://www.linkedin.com/in/kristen-yeon-ji-yun-72112591/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
		      </ul>
		    </li>
		  </ul>
		</section>
	  </div>
	</div>
      </section>

    </div>

    <!-- Footer -->
    <footer id="footer" class="wrapper style1-alt">
      <div class="inner">
	<ul class="menu">
	  <li>&copy; Purdue AIM 2024. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a>, modified by Tim Nadolsky</li>
	  <li> <a href="http://html5up.net/license">Creative Commons</a>.</p>
</ul>
</div>
</footer>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>
