<!DOCTYPE HTML>
<html lang="en">

<head>
	<title>2025 AAAI Workshop AI for Music</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<meta name="description"
		content="Join the 2025 AAAI Workshop on Artificial Intelligence for Music, exploring the intersection of AI and music creation, recognition, education, and more.">
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">
	<!-- Sidebar -->
	<section id="sidebar">
		<div class="inner">

			<nav>

				<ul>
					<li><a href="index.html#intro"><img src="images/aim.png" width="50" alt="Workshop Logo"></a></li>
					<li><a href="index.html#evaluator">Our Projects</a></li>
					<li><a href="index.html#activities">Research Areas</a></li>
					<li><a href="index.html#who">Leaders</a></li>
					<li><a href="index.html#outreach">Outreach</a></li>
					<li><a href="index.html#vipteam">VIP Team</a></li>
					<li><a href="index.html#contact">Contact</a></li>
					<li><a href="#call-for-papers">Call for Papers</a></li> <!-- Added Navigation Link -->
				</ul>
			</nav>
		</div>
	</section>

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Main -->
		<section id="main" class="wrapper style5">
			<div class="inner">
				<h1 class="major">Artificial Intelligence for Music</h1>

				A workshop at <a href="https://aaai.org/conference/aaai/aaai-25/" target="_blank"
					rel="noopener noreferrer">2025 AAAI Annual Conference</a>

				<!-- Summary -->

				<section>
					<h2> 2025/03/03 Monday</h2>
					<h2>Workshop Summary</h2>
					<p>This one-day workshop will explore the dynamic intersection of artificial intelligence and music.
						It explores how AI is transforming music creation, recognition, and education, ethical and legal
						implications, as well as business opportunities.
						We will investigate how AI is changing the music industry and education—from composition to
						performance, production, collaboration, and audience experience.
						Participants will gain insights into the technological challenges in music and how AI can
						enhance creativity, enabling musicians and producers to push the boundaries of their art.
						The workshop will cover topics such as AI-driven music composition, where algorithms generate
						melodies, harmonies, and even full orchestral arrangements. We will discuss how AI tools assist
						in sound design, remixing, and mastering, allowing for new sonic possibilities and efficiencies
						in music production.
						Additionally, we'll examine AI's impact on music education and the careers of musicians,
						exploring advanced learning tools and teaching methods. AI technologies are increasingly adopted
						in the music and entertainment industry.
						The workshop will also discuss the legal and ethical implications of AI in music, including
						questions of authorship, originality, and the evolving role of human artists in an increasingly
						automated world. This workshop is designed for AI researchers, musicians, producers, and
						educators interested in the current status and future of AI in music.</p>
				</section>

				<section>
					<h2>Topics</h2>
					<ul>
						<li>Impacts of AI on music education and careers of musicians.</li>
						<li>AI-driven music composition.</li>
						<li>AI-assisted sound design.</li>
						<li>AI-generated audio and video.</li>
						<li>Legal and ethical considerations of AI in music.</li>
					</ul>
				</section>


				<!-- Schedule -->
				<section>
					<h2>Schedule</h2>

					<table style="width:100%">
						<tr>
							<th>Time</th>
							<th>Topic</th>
						</tr>
						<tr>
							<td>09:00AM</td>
							<td>Welcome by Organizers</td>
						</tr>
						<tr>
							<td>09:10AM</td>
							<td>Invited Speech by Zhiyao Duan</td>
						</tr>

						<tr>
							<td>09:50AM</td>
							<td>Invited Speech by Miguel Willis</td>
						</tr>
						<tr>
							<td>10:30AM</td>
							<td>Break</td>
						</tr>

						<tr>
							<td>11:00AM</td>
							<td>Paper Presentations (selected from submissions)</td>
						</tr>

						<tr>
							<td>12:00PM</td>
							<td>Lunch Break</td>
						</tr>

						<tr>
							<td>01:00PM</td>
							<td>Invited Speech by Hao-Wen Dong</td>
						</tr>

						<tr>
							<td>01:40PM</td>
							<td>Invited Speech by Gus Xia</td>
						</tr>

						<tr>
							<td>02:20PM</td>
							<td>Panel Discussion by the Invited Speakers</td>
						</tr>

						<tr>
							<td>03:20PM</td>
							<td>Break</td>
						</tr>

						<tr>
							<td>03:30PM</td>
							<td>Paper Presentations (selected from submissions)</td>
						</tr>

						<tr>
							<td>04:30PM</td>
							<td>Open Discussion: Future of AI and Music</td>
						</tr>

						<tr>
							<td>05:00PM</td>
							<td>Adjourn</td>
						</tr>
					</table>

				</section>
				<!-- Schedule -->


				<!-- Call for Papers -->
				<section id="call-for-papers">
					<div class="inner">
						<h2>Call for Papers</h2>

						<h3>Submission Requirements</h3>
						<p>
							Submissions should be a maximum of 6 pages without references. Work in progress is welcome. Authors are
							encouraged to include descriptions of their prototype implementations. Additionally, authors
							are encouraged to interact with workshop attendees by including posters or demonstrations at
							the end of the workshop. Conceptual designs without any evidence of practical implementation
							are discouraged.
						</p>

						<h3>Topics of Interest</h3>
						<ul>
							<li>AI-Driven Music Composition and Generation</li>
							<li>AI in Music Practice and Performance</li>
							<li>AI-based Music Recognition and Transcription</li>
							<li>AI Applications in Sound Design</li>
							<li>AI-Generated Videos to Accompany Music</li>
							<li>AI-Generated Lyrics Based on Music</li>
							<li>Legal or Ethical Implications of AI on Music</li>
							<li>AI's Impacts on Musicians’ Careers</li>
							<li>AI Assisted Music Education</li>
							<li>Business Opportunities of AI and Music</li>
							<li>Music Datasets and Data Analysis</li>
						</ul>

						<h3>Paper Format</h3>
						<p>
							Please follow the format required by AAAI at
							<a href="https://aaai.org/conference/aaai/aaai-25/aaai-25-main-technical-call-for-papers/"
								target="_blank" rel="noopener noreferrer">
								AAAI 2025 Main Technical Call for Papers
							</a>.
						</p>

						<h3>Submission Site Information</h3>
						<p>
							Please submit your papers through the <a
								href="https://cmt3.research.microsoft.com/AI4Music2025" target="_blank"
								rel="noopener noreferrer">CMT Submission Portal</a>.
						</p>

						<h3>Important Dates</h3>
						<ul>
							<li><strong>Submission Deadline:</strong> November 22, 2024</li>
							<li><strong>Notification of Acceptance:</strong> December 9, 2024</li>
							<li><strong>Final Version Due:</strong> December 31, 2024</li>
						</ul>

						<p>
							Accepted papers will be posted on the workshop website.
						</p>
					</div>
				</section>
				<!-- Invited Speakers -->
				<section>
					<h2>Invited Speakers</h2>

					<!-- Speaker 1: Hao-Wen (Herman) Dong -->
					<section class="wrapper style5 spotlights">
						<section>
							<a href="https://hermandong.com/" class="image" target="_blank" rel="noopener noreferrer">
								<img src="https://hermandong.com/profile.jpg" width="400" alt="Hao-Wen (Herman) Dong"
									data-position="top center" />
							</a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://hermandong.com/" target="_blank"
											rel="noopener noreferrer">Hao-Wen (Herman) Dong</a></h2>
									<p>Hao-Wen (Herman) Dong is an Assistant Professor in the Performing Arts Technology
										Department at the University of Michigan. Herman’s research aims to empower
										music and audio creation with machine learning. His long-term goal is to lower
										the barrier of entry for music composition and democratize audio content
										creation. He is broadly interested in music generation, audio synthesis,
										multimodal machine learning, and music information retrieval. Herman received
										his PhD degree in Computer Science from the University of California San Diego,
										where he worked with Julian McAuley and Taylor Berg-Kirkpatrick. His research
										has been recognized by the UCSD CSE Doctoral Award for Excellence in Research,
										KAUST Rising Stars in AI, UChicago and UCSD Rising Stars in Data Science, ICASSP
										Rising Stars in Signal Processing, and UCSD GPSA Interdisciplinary Research
										Award.</p>
								</div>
							</div>
						</section>

						<!-- Speaker 2: Zhiyao Duan -->
						<section>
							<a href="https://www.hajim.rochester.edu/ece/people/faculty/duan_zhiyao/index.html"
								class="image" target="_blank" rel="noopener noreferrer">
								<img src="https://hajim.rochester.edu/ece/sites/zduan/resource/ZhiyaoDuan2018_web.jpg" width="400" alt="Zhiyao Duan" data-position="top center" />
							</a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://www.hajim.rochester.edu/ece/people/faculty/duan_zhiyao/index.html"
											target="_blank" rel="noopener noreferrer">Zhiyao Duan</a></h2>
									<p>Zhiyao Duan is an associate professor in Electrical and Computer Engineering,
										Computer Science, and Data Science at the University of Rochester. He is also a
										co-founder of Violy, a company aiming to improve music education through AI. His
										research interest is in computer audition and its connections with computer
										vision, natural language processing, and augmented and virtual reality. He
										received a best paper award at the Sound and Music Computing (SMC) Conference in
										2017, a best paper nomination at the International Society for Music Information
										Retrieval (ISMIR) Conference in 2017, and a CAREER award from the National
										Science Foundation (NSF). His work has been funded by NSF, National Institute of
										Health, National Institute of Justice, New York State Center of Excellence in
										Data Science, and University of Rochester internal awards on AR/VR, health
										analytics, and data science. He is a senior area editor of IEEE Signal
										Processing Letters, an associate editor for IEEE Open Journal of Signal
										Processing, and a guest editor for Transactions of the International Society for
										Music Information Retrieval. He is the President of ISMIR.</p>
								</div>
							</div>
						</section>

						<!-- Speaker 3: Miguel Willis -->
						<section>
							<a href="https://www.law.upenn.edu/faculty/willism1" class="image" target="_blank"
								rel="noopener noreferrer">
								<img src="https://www.law.upenn.edu/live/image/gid/35/width/518/height/576/crop/1/src_region/0,0,663,664/43301_Miguel_Willis.rev.1646392650.png" width="400" alt="Miguel Willis" data-position="top center" />
							</a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://www.law.upenn.edu/faculty/willism1" target="_blank"
											rel="noopener noreferrer">Miguel Willis</a></h2>
									<p>Miguel Willis is the Innovator in Residence at the Law School’s Future of the
										Profession Initiative (FPI), University of Pennsylvania. He concurrently serves
										as the Executive Director of Access to Justice Tech Fellows, a national
										nonprofit organization that develops summer fellowships for law students seeking
										to leverage technology to create equitable legal access for low-income and
										marginalized populations. Prior to joining FPI, Willis served as the Law School
										Admissions Council's (LSAC) inaugural Presidential Innovation Fellow. Willis
										currently serves on the advisory board of the University of Arizona James E.
										Rogers College of Law’s Innovation for Justice (i4J) program and serves on The
										Legal Services Corporation’s Emerging Leaders Council.</p>
								</div>
							</div>
						</section>

						<!-- Speaker 4: Gus Xia -->
						<section>
							<a href="https://mbzuai.ac.ae/study/faculty/dr-gus-xia/" class="image" target="_blank"
								rel="noopener noreferrer">
								<img src="https://mbzuai.ac.ae/wp-content/uploads/2022/06/profile_gus-xia_secondary.jpg" width="400" alt="Gus Xia" data-position="top center" />
							</a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://mbzuai.ac.ae/study/faculty/dr-gus-xia/" target="_blank"
											rel="noopener noreferrer">Gus Xia</a></h2>
									<p>Gus Xia is an assistant professor of Machine Learning at the Mohamed bin Zayed
										University of Artificial Intelligence in Masdar City, Abu Dhabi. His research
										includes the design of interactive intelligent systems to extend human musical
										creation and expression. This research lies at the intersection of machine
										learning, human-computer interaction, robotics, and computer music. Some
										representative works include interactive composition via style transfer,
										human-computer interactive performances, autonomous dancing robots, large-scale
										content-based music retrieval, haptic guidance for flute tutoring, and bio-music
										computing using slime mold.</p>
								</div>
							</div>
						</section>

					</section>
				</section>


				<!-- Organizers -->
				<section>
					<h2>Organizers</h2>
					<p>Meet the team behind the 2025 AAAI Workshop on Artificial Intelligence for Music.</p>
					<section id="organizers" class="wrapper style5 spotlights">

						<!-- Organizer 1 -->
						<section>
							<a href="#" class="image"><img
									src="https://engineering.purdue.edu/ResourceDB/ResourceFiles/image277153"
									width="400" alt="Yung Hsiang Lu" data-position="top
		center" /></a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://yhlu.net/" target="_blank"
											rel="noopener noreferrer">Yung-Hsiang Lu</a></h2>
									<h3>Professor of Electrical and Computer Engineering</h3>
									<p>
										Yung-Hsiang Lu is a professor in the Elmore
										Family School of Electrical and Computer
										Engineering at Purdue University. He is a fellow
										of the IEEE and a distinguished scientist of the
										ACM. Yung-Hsiang has published papers on
										computer vision and machine learning in venues
										such as AI Magazine, Nature Machine Learning,
										and Computer. He is one of the editors of the
										book "Low-Power Computer Vision: Improve the
										Efficiency of Artificial Intelligence" (ISBN
										9780367744700, 2022 by Chapman & Hall).
									</p>
								</div>
							</div>
						</section>

						<!-- Organizer 2 -->
						<section>
							<a href="#" class="image"><img src="images/yun.jpg" width="400" alt="Kristen Yeon-Ji Yun"
									data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://kristenyeonjiyun.com/" target="_blank"
											rel="noopener noreferrer">Kristen Yeon-Ji Yun</a></h2>
									<h3>Clinical Associate Professor of Music</h3>
									<p>
										Kristen Yeon-Ji Yun is a clinical associate
										professor in the Department of Music at the
										Patti and Rusty Rueff School of Design, Art, and
										Performance at Purdue University. She is the
										Principal Investigator of the research project
										"Artificial Intelligence Technology for Future
										Music Performers" (US National Science
										Foundation, IIS 2326198). Kristen is an active
										soloist, chamber musician, musical scholar, and
										clinician. She has toured many countries,
										including Malaysia, Thailand, Germany, Mexico,
										Japan, China, Hong Kong, Spain, France, Italy,
										Taiwan, and South Korea, giving a series of
										successful concerts and master classes.
									</p>
								</div>
							</div>
						</section>

						<!-- Organizer 3 -->
						<section>
							<a href="#" class="image"><img
									src="https://gkt.sh/content/images/size/w1140/2024/06/George_Thiruvathukal-2-1.jpg"
									width="400" alt="George K. Thiruvathukal" data-position="top center" /></a>

							<div class="content">
								<div class="inner">
									<h2><a href="https://gkt.sh/" target="_blank" rel="noopener noreferrer">George K.
											Thiruvathukal</a></h2>
									<h3>Professor and Chairperson of Computer Science</h3>
									<p>
										George K. Thiruvathukal is a professor and
										chairperson of Computer Science at Loyola
										University Chicago and a visiting computer
										scientist at Argonne National Laboratory. His
										research interests include high-performance
										computing and distributed systems, programming
										languages, software engineering, machine
										learning, digital humanities, and arts
										(primarily music). George has published multiple
										books, including "Software Engineering for
										Science" (ISBN 9780367574277, 2016 Chapman and
										Hall & CRC), "Web Programming: Techniques for
										Integrating Python, Linux, Apache, and MySQL"
										(ISBN 9780130410658, 2001 Prentice Hall), and
										"High-Performance Java Platform Computing:
										Multithreaded and Networked Programming" (ISBN
										9780130161642, 2000 Prentice Hall).
									</p>
								</div>
							</div>
						</section>

						<!-- Organizer 4 -->
						<section>
							<a href="#" class="image"><img src="images/benchou.jpg" width="400"
									alt="Benjamin Shiue-Hal Chou" data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2><a href="https://www.linkedin.com/in/benjamin-chou-6aa058228/" target="_blank"
											rel="noopener noreferrer">Benjamin Shiue-Hal Chou</a></h2>
									<h3>PhD Student and Lab Graduate Mentor</h3>
									<p>
										Benjamin Shiue-Hal Chou is a PhD student in
										Electrical and Computer Engineering at Purdue
										University, supervised by Dr. Yung-Hsiang
										Lu. His research focuses on artificial
										intelligence applications in music technology,
										particularly on detecting errors in music
										performances. Benjamin has co-authored “Token
										Turing Machines are Efficient Vision Models”
										(arXiv preprint arXiv:2409.07613, 2024). He
										earned his Bachelor of Science in Electrical
										Engineering from National Cheng Kung University
										(NCKU) in Taiwan, receiving awards such as the
										Outstanding Student Scholarship, Transnational
										Research Scholarship Grant, and the Tainan City
										Digital Governance Talent Award.
									</p>
								</div>
							</div>
						</section>

						<!-- Add additional organizers following the same structure -->

					</section>


				</section>

			</div>
		</section>
	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>