<!DOCTYPE HTML>
<html>

<head>
	<title>2025 AAAI Workshop AI for Music</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">
	<!-- Sidebar -->
    <section id="sidebar">
		<div class="inner">
		  
	  <nav>
		  
		<ul>
			<li><a href="index.html#intro"><img src="images/aim.png" width=50></img></a></li>
			<li><a href="index.html#evaluator">Our Projects</a></li>
			<li><a href="index.html#activities">Research Areas</a></li>
			<li><a href="index.html#who">Leaders</a></li>
			<li><a href="index.html#outreach">Outreach</a></li>
			<li><a href="index.html#vipteam">VIP Team</a></li>
			<li><a href="index.html#contact">Contact</a></li>
		</ul>
	  </nav>
		</div>
	  </section>

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Main -->
		<section id="main" class="wrapper style5">
			<div class="inner">
			  <h1 class="major">Artificial Intelligence for Music</h1>

			  A workshop at <a href="https://aaai.org/conference/aaai/aaai-25/">2025 AAAAI Annual Conferece</a>

				<!-- Summary -->

				<section>
				  <h2>Workshop Summary</h2>
				  <p>This workshop will explore the
				  dynamic intersection of artificial
				  intelligence and music. Music is one
				  of the most common formats of
				  communication, entertainment, and
				  expressions. Producing,
				  understanding, and processing music
				  present many challenges in
				  artificial intelligence. This
				  workshop investigates how AI is
				  changing the music industry and
				  education, from composition to
				  performance, production,
				  collaboration, and audience
				  experience. Participants will gain
				  insights into the technological
				  problems from music and the ways AI
				  can enhance creativity and enable
				  musicians and producers to push the
				  boundaries of their art. The
				  workshop will also discuss AI's
				  impacts on music education and
				  careers of musicians. We will cover
				  topics such as AI-driven music
				  composition, where algorithms
				  generate melodies, harmonies, and
				  even full orchestral
				  arrangements. The workshop will
				  discuss how AI tools can assist in
				  sound design, remixing, and
				  mastering, allowing for new sonic
				  possibilities and efficiencies in
				  music production. Artificial
				  intelligence may provide a rich user
				  experience combining sound and
				  visual effects. Additionally, the
				  workshop will discuss the legal and
				  ethical implications of AI in music,
				  including questions of authorship,
				  originality, and the role of human
				  artists in an increasingly automated
				  world. This workshop is designed for
				  AI researchers, musicians,
				  producers, and educators interested
				  in the status and future of AI for
				  music. .</p>
				</section>


				<!-- Schedule -->
				<section>
				  <h2>Schedule</h2>

				  <table style="width:100%">
				    <tr>
				      <th>Time</th>
				      <th>Topic</th>
				    </tr>
				    <tr>
				      <td> 09:00AM </td>
				      <td> Welcome by Organizers </td>
				    </tr>
				    <tr>
				      <td> 09:10AM </td>
				      <td> Invited Speech by Zhiyao Duan </td> 
				    </tr>

				    <tr>
				      <td> 09:50AM </td>
				      <td> Invited Speech by Miguel Willis              </td>
				    </tr>
				    <tr>
				      <td> 10:30AM </td>
				      <td> Break                                        </td>
				    </tr>

				    <tr>
				      <td> 11:00AM </td>
				      <td> Paper Presentations (selected from submissions)  </td>
				    </tr>

				    <tr>
				      <td> 12:00PM </td>
				      <td> Lunch Break                                  </td>
				    </tr>

				    <tr>
				      <td> 01:00PM </td>
				      <td> Invited Speech by Hao-Wen Dong               </td>
				    </tr>

				    <tr>
				      <td> 01:40PM </td>
				      <td> Invited Speech by Gus Xia                    </td>
				    </tr>

				    <tr>
				      <td> 02:20PM </td>
				      <td> Panel Discussion by the Invited Speakers     </td>
				    </tr>

				    <tr>
				      <td> 03:20PM </td>
				      <td> Break                                        </td>
				    </tr>

				    <tr>
				      <td> 03:30PM </td>
				      <td> Paper Presentations (selected from submissions)  </td>
				    </tr>

				    <tr>
				      <td> 04:30PM </td>
				      <td> Open Discussion: Future of AI and Music      </td>
				    </tr>

				    <tr>
				      <td> 05:00PM </td>
				      <td> Adjourn </td>
				    </tr>
				  </table>
				  
				</section>

				<!-- Invited Speakers -->
				<section>
					<h2>Invited Speakers</h2>
					<p><a href="https://hermandong.com/">Hao-Wen
					  (Herman) Dong</a> is an
					  Assistant Professor in the
					  Performing Arts Technology
					  Department at University of
					  Michigan. Herman’s research
					  aims to empower music and
					  audio creation with machine
					  learning. His long-term goal
					  is to lower the barrier of
					  entry for music composition
					  and democratize audio
					  content creation. He is
					  broadly interested in music
					  generation, audio synthesis,
					  multimodal machine learning,
					  and music information
					  retrieval. Herman received
					  his PhD degree in Computer
					  Science from University of
					  California San Diego, where
					  he worked with Julian
					  McAuley and Taylor
					  Berg-Kirkpatrick. Herman’s
					  research has been recognized
					  by the UCSD CSE Doctoral
					  Award for Excellence in
					  Research, KAUST Rising Stars
					  in AI, UChicago and UCSD
					  Rising Stars in Data
					  Science, ICASSP Rising Stars
					  in Signal Processing and
					  UCSD GPSA Interdisciplinary
					  Research Award.
					</p>
					<p><a href="https://www.hajim.rochester.edu/ece/people/faculty/duan_zhiyao/index.html">Zhiyao
					    Duan</a> is an associate
					    professor in Electrical
					    and Computer Engineering,
					    Computer Science, and Data
					    Science at University of
					    Rochester. He is also a
					    co-founder of Violy, a
					    company aiming to improve
					    music education through
					    AI. His research interest
					    is in computer audition
					    and its connections with
					    computer vision, natural
					    language processing, and
					    augmented and virtual
					    reality. He received a
					    best paper award at the
					    Sound and Music Computing
					    (SMC) Conference in 2017,
					    a best paper nomination at
					    the International Society
					    for Music Information
					    Retrieval (ISMIR)
					    Conference in 2017, and a
					    CAREER award from the
					    National Science
					    Foundation (NSF). His work
					    has been funded by NSF,
					    National Institute of
					    Health, National Institute
					    of Justice, New York State
					    Center of Excellence in
					    Data Science, and
					    University of Rochester
					    internal awards on AR/VR,
					    health analytics, and data
					    science. He is a senior
					    area editor of IEEE Signal
					    Processing Letters, an
					    associate editor for IEEE
					    Open Journal of Signal
					    Processing, and a guest
					    editor for Transactions of
					    the International Society
					    for Music Information
					    Retrieval. He is the
					    President of ISMIR.</p>

					<p><a href="https://www.law.upenn.edu/faculty/willism1">
					  Miguel Willis</a> is the
					  Innovator in Residence at
					  the Law School’s Future of
					  the Profession Initiative
					  (FPI), University of
					  Pennsylvania. He
					  concurrently serves as the
					  Executive Director of Access
					  to Justice Tech Fellows, a
					  national nonprofit
					  organization that develops
					  summer fellowships for law
					  students seeking to leverage
					  technology to create
					  equitable legal access for
					  low-income and marginalized
					  populations. Prior to
					  joining FPI, Willis served
					  as the Law School Admissions
					  Council's (LSAC) inaugural
					  Presidential Innovation
					  Fellow. Willis currently
					  serves on the advisory board
					  of University of Arizona
					  James E. Rogers College of
					  Law’s Innovation for Justice
					  (i4J) program and serves on
					  The Legal Services
					  Corporation’s Emerging
					  Leaders Council.

					</p>

					<p> <a href="https://mbzuai.ac.ae/study/faculty/dr-gus-xia/">Gus
					  Xia </a> is an assistant
					  professor of Machine
					  Learning at the Mohamed bin
					  Zayed University of
					  Artificial Intelligence in
					  Masdar City, Abu Dhabi. His
					  research includes the design
					  of interactive intelligent
					  systems to extend human
					  musical creation and
					  expression. This research
					  lies in the intersection of
					  machine learning,
					  human-computer interaction,
					  robotics, and computer
					  music. Some representative
					  works include interactive
					  composition via style
					  transfer, human-computer
					  interactive performances,
					  autonomous dancing robots,
					  large-scale content-based
					  music retrieval, haptic
					  guidance for flute tutoring,
					  and bio-music computing
					  using slime mold.

					</p>
					
				</section>
				
				
				<!-- Organizers -->
				<section>
					<h2>Organizers</h2>
					<p><a href="https://yhlu.net/">Yung-Hsiang
					Lu</a> is a professor in the
					Elmore Family School of
					Electrical and Computer
					Engineering at Purdue
					University. He is a fellow of
					the IEEE and distinguished
					scientist of the ACM. He has
					published papers on topics
					about computer vision and
					machine learning in venues
					such as AI Magazine, Nature
					Machine Learning, and
					Computer.  He is one of the
					editors of the book
					  "Low-Power Computer Vision:
					Improve the Efficiency of
					Artificial Intelligence"
					(ISBN 9780367744700, 2022 by
					Chapman & Hall).
					  
					</p>
					<p> <a href="https://kristenyeonjiyun.com/">Kristen
					  Yeon-Ji Yun</a> is a
					  clinical associate professor
					  in the Department of Music
					  in the Patti and Rusty Rueff
					  School of Design, Art, and
					  Performance at Purdue
					  University. She is the
					  Principal Investigator of a
					  research project "Artificial
					  Intelligence Technology for
					  Future Music Performers" (US
					  National Science Foundation,
					  IIS 2326198). She is an
					  active soloist, chamber
					  musician, musical scholar,
					  and clinician.  has toured
					  many countries including
					  Malaysia, Thailand, Germany,
					  Mexico, Japan, China,
					  Hong-Kong, Spain, France,
					  Italy, Taiwan, and South
					  Korea giving a series of
					  successful concerts and
					  master classes.</p>

					<p><a href="https://gkt.sh/">George
					K. Thiruvathukal</a> is professor and chairperson of Computer Science
					at Loyola University Chicago and visiting computer scientist at
					Argonne National Laboratory. His research interests include
					high-performance computing and distributed systems, programming
					languages, software engineering, machine learning, digital humanities
					and arts (primarily music). He has published multiple books, including
					"Software Engineering for Science" (ISBN 9780367574277, 2016 Chapman
					and Hall & CRC), "Web Programming: Techniques for Integrating Python,
					Linux, Apache, and Mysql" (ISBN 9780130410658, 2001 Prentice Hall),
					"High-Performance Java Platform Computing: Multithreaded and Networked
					Programming" (ISBN 9780130161642, 2000 Prentice Hall).
					</p>				
					<!-- <img src="images/benchou.jpg" width="400" alt="Benjamin Shiue-Hal Chou" data-position="top center" /> -->
					<p><a href="https://www.linkedin.com/in/benjamin-chou-6aa058228/">Benjamin Shiue-Hal Chou</a> 
					is a PhD student in Electrical and Computer Engineering at Purdue University, supervised by Dr. Yung Hsiang Lu. His research focuses on artificial intelligence applications in music technology. He is currently working on detecting errors in music performances. 
					He has co-authored “Token Turing Machines are Efficient Vision Models” (arXiv preprint arXiv:2409.07613, 2024).
					Benjamin earned his Bachelor of Science in Electrical Engineering from National Cheng Kung University (NCKU) in Taiwan. He received awards including the Outstanding Student Scholarship, Transnational Research Scholarship Grant, and the Tainan City Digital Governance Talent Award.</p>
	

				</section>

					
				</section>

			</div>
		</section>
	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>
